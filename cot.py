# Chain of Thought í†µí•© íŒŒì´í”„ë¼ì¸
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnableSequence, RunnableMap
from langchain_community.vectorstores import FAISS, DistanceStrategy
from langchain.document_loaders import PyPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
import pandas as pd
import os
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.chat_models import AzureChatOpenAI
from langchain.schema.runnable import RunnableLambda
import time
import json
import re
import numpy as np
from langchain.schema import Document
from sklearn.metrics.pairwise import cosine_similarity

def timed(name):
    def wrapper(fn):
        def inner(x):
            print(f"â±ï¸ [{name}] ì‹œì‘")
            start = time.time()
            result = fn(x)
            end = time.time()
            print(f"âœ… [{name}] ì™„ë£Œ - ì†Œìš” ì‹œê°„: {end - start:.2f}ì´ˆ")
            return result
        return inner
    return wrapper

# í™˜ê²½ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "sk-"


# LLM ì„¤ì •
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('./all_origin_updated.csv', encoding='utf-8-sig')

# ë°ì´í„° ë¡œë“œ ë° ë²¡í„°DB êµ¬ì¶• (ê¸°ì¡´ê³¼ ë™ì¼)
def setup_vectordb(df):
    corpus_df = df[["ticket_id_hashed", "generated_summary"]].dropna(subset=["generated_summary"])
    
    documents = [
        Document(
            page_content=row["generated_summary"],
            metadata={"ticket_id": row["ticket_id_hashed"], "doc_id": f"doc_{i}"}
        )
        for i, (_, row) in enumerate(corpus_df.iterrows())
    ]
    
    vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())
    return vectordb, documents

# Chain of Thought í†µí•© í”„ë¡¬í”„íŠ¸
cot_prompt = PromptTemplate.from_template("""
<Role>
ë‹¹ì‹ ì€ ì œí’ˆ í”¼ë“œë°±ì„ ë¶„ì„í•˜ê³  ê°€ì¥ ìœ ì‚¬í•œ ê¸°ì¡´ ì‚¬ë¡€ë¥¼ ì°¾ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì²´ê³„ì ì¸ ì‚¬ê³  ê³¼ì •ì„ í†µí•´ ë‹¨ê³„ë³„ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
</Role>

<Task>
ì£¼ì–´ì§„ ì œí’ˆ í”¼ë“œë°±ì— ëŒ€í•´ ë‹¤ìŒ ì‚¬ê³  ê³¼ì •ì„ ë”°ë¼ ë¶„ì„í•˜ì„¸ìš”:

**ì…ë ¥ ì •ë³´:**
- ì»´í¬ë„ŒíŠ¸: {components}
- í”¼ë“œë°± ë‚´ìš©: {generated_summary}
- ìƒìœ„ 10ê°œ ìœ ì‚¬ ë¬¸ì„œ: {top_10_documents}

**ë¶„ì„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì‚¬ê³ í•˜ì„¸ìš”:**

**Step 1: í”¼ë“œë°± ìœ í˜• íŒë‹¨**
ë¨¼ì € ì´ í”¼ë“œë°±ì´ ì–´ë–¤ ìœ í˜•ì¸ì§€ íŒë‹¨í•´ë³´ê² ìŠµë‹ˆë‹¤.
- ì‹ ê·œ ê¸°ëŠ¥ ìš”ì²­ì´ë‚˜ ê°œì„  ì œì•ˆì¸ê°€ìš”? â†’ "Proposal"
- ì˜¤ë¥˜, ê³ ì¥, ê²°í•¨, ë¶ˆë§Œ, ë¶ˆí¸, ë¶ˆì¾Œ, ë‹¨ìˆœë¬¸ì˜, ì˜ê²¬ ë“±ì¸ê°€ìš”? â†’ "ICC"

í”¼ë“œë°± ë‚´ìš©ì„ ë¶„ì„í•´ë³´ë‹ˆ...
[ì—¬ê¸°ì„œ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ì„ ì‘ì„±]

**íŒë‹¨ ê²°ê³¼:** [Proposal ë˜ëŠ” ICC]

**Step 2: ì œì•ˆì‚¬í•­ ë¶„ë¦¬ (Proposalì¸ ê²½ìš°ë§Œ)**
ë§Œì•½ Proposalì´ë¼ë©´, ì—¬ëŸ¬ ê°œì˜ ì œì•ˆì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.
- "and", êµ¬ë‘ì , ì—¬ëŸ¬ ë¬¸ì¥ ë“±ì„ í†µí•´ êµ¬ë¶„ë˜ëŠ” ë³„ê°œì˜ ì•„ì´ë””ì–´ê°€ ìˆëŠ”ì§€ ì‚´í´ë´…ë‹ˆë‹¤.

ë¶„ì„ ê²°ê³¼...
[ì‚¬ê³  ê³¼ì •]

**ë¶„ë¦¬ëœ ì œì•ˆë“¤:** [JSON ë°°ì—´ í˜•íƒœ]

**Step 3: ì²« ë²ˆì§¸ ì œì•ˆ ì„ íƒ**
ì—¬ëŸ¬ ì œì•ˆ ì¤‘ ì›ë¬¸ì—ì„œ ì²« ë²ˆì§¸ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ì œì•ˆì„ ì„ íƒí•˜ê² ìŠµë‹ˆë‹¤.

**ì„ íƒëœ ì²« ë²ˆì§¸ ì œì•ˆ:** [í…ìŠ¤íŠ¸]

**Step 4: ì œì•ˆë¬¸ í‘œì¤€í™”**
ì„ íƒëœ ì œì•ˆì„ í‘œì¤€í™”ëœ í˜•íƒœë¡œ ìš”ì•½í•˜ê² ìŠµë‹ˆë‹¤.
- "The user suggests"ë¡œ ì‹œì‘í•˜ëŠ” ì˜ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
- ì»´í¬ë„ŒíŠ¸ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë§¥ë½ ë³´ê°•

**í‘œì¤€í™”ëœ ì œì•ˆë¬¸:** [ì˜ì–´ ë¬¸ì¥]

**Step 5: ìœ ì‚¬ë„ ë¶„ì„**
ìƒìœ„ 10ê°œ ë¬¸ì„œì™€ì˜ ìœ ì‚¬ì„±ì„ ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤.
ê° ë¬¸ì„œì— ëŒ€í•´:
- ê¸°ëŠ¥ ë²”ì£¼ì˜ ì¼ì¹˜ì„±
- ìš”êµ¬ì‚¬í•­ì˜ ìœ ì‚¬ì„±  
- í•´ê²°ë°©ì•ˆì˜ ê´€ë ¨ì„±
ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

**Step 6: Self-Consistency ê²€ì¦ (3íšŒ ë°˜ë³µ)**
ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì„ íƒí•˜ê¸° ìœ„í•´ 3ë²ˆì˜ ë…ë¦½ì ì¸ íŒë‹¨ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤.

**1ë²ˆì§¸ íŒë‹¨:**
- ê¸°ëŠ¥ ë²”ì£¼ ì¼ì¹˜ì„±: [0-25ì ]
- Claim ì»¤ë²„ë¦¬ì§€: [0-25ì ] 
- ê·¼ê±° ì¶©ì‹¤ë„: [0-25ì ]
- ì„¤ëª… íë¦„ ìœ ì‚¬ì„±: [0-25ì ]
- í‰ê°€ ì´ì : [0-100ì ]
- ì„ íƒ ë¬¸ì„œ: [ticket_id]
- ì‹ ë¢°ë„: [0-100%]

**2ë²ˆì§¸ íŒë‹¨:**
[ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë°˜ë³µ]

**3ë²ˆì§¸ íŒë‹¨:**
[ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë°˜ë³µ]

**Step 7: ìµœì¢… í†µí•© íŒë‹¨**
3ë²ˆì˜ íŒë‹¨ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•˜ê² ìŠµë‹ˆë‹¤.

í†µí•© í‰ê°€ ê¸°ì¤€:
1. Self-Consistency í‰ê·  ì‹ ë¢°ë„ (ê°€ì¤‘ì¹˜ 0.3)
2. ë™ì¼ ë¬¸ì„œ ë°˜ë³µ ì„ íƒ ì—¬ë¶€ (+10ì  ë³´ì •)
3. Self-Consistency íŒë‹¨ ì´ì  í‰ê·  (ê°€ì¤‘ì¹˜ 0.2)
4. RAG ê¸°ë°˜ Cosine ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 0.2)
5. Faithfulness (ê°€ì¤‘ì¹˜ 0.15)
6. Context Recall (ê°€ì¤‘ì¹˜ 0.15)

**ìµœì¢… ê²°ë¡ :**

> âœ… ìµœì¢… ì¶”ì²œ ë¬¸ì„œ: [ë¬¸ì„œì˜ Ticket ID]
> ğŸ“„ ì„ íƒëœ ë¬¸ì„œ ìš”ì•½: [í•µì‹¬ ë‚´ìš© ìš”ì•½]
> ğŸ”’ ì¶”ì²œ ì‹ ë¢°ë„ (%): [0~100 ì‚¬ì´ ìˆ˜ì¹˜]
> ğŸ“Š RAG ê¸°ë°˜ ìœ ì‚¬ë„ (%): [ìœ ì‚¬ë„ ì ìˆ˜]
> ğŸ§  ì„ íƒ ê·¼ê±° ìš”ì•½:
> - [êµ¬ì²´ì ì¸ ì„ íƒ ì´ìœ ë“¤]
> - [ì‹ ë¢°ë„ ê·¼ê±°]
> - [ìœ ì‚¬ì„± ë¶„ì„ ê²°ê³¼]

**ì‚¬ê³  ê³¼ì • ì™„ë£Œ**
""")

# ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
def calculate_cosine_similarity(query, documents, embedding_model):
    index = vectordb.index
    stored_vectors = index.reconstruct_n(0, index.ntotal)
    stored_vectors_np = np.array(stored_vectors)

    query_vector = embedding_model.embed_query(query)
    query_vector_np = np.array(query_vector).reshape(1, -1)

    similarities = cosine_similarity(query_vector_np, stored_vectors_np)[0]
    return similarities

def retrieve_context(proposal):
    embedding_model = OpenAIEmbeddings()
    similarities = calculate_cosine_similarity(proposal, documents, embedding_model)
    top_k_indices = similarities.argsort()[::-1][:10]

    formatted_docs = []
    for idx, i in enumerate(top_k_indices, start=1):
        doc = documents[i]
        score = similarities[i]
        ticket_id = doc.metadata.get("ticket_id", "N/A")
        summary = doc.page_content.strip()[:100]
        
        formatted_docs.append(
            f"ë¬¸ì„œ {idx}: Ticket ID [{ticket_id}], ìœ ì‚¬ë„: {score:.4f}, ë‚´ìš©: {summary}..."
        )
    
    return "\n".join(formatted_docs)

# Chain of Thought íŒŒì´í”„ë¼ì¸
def cot_pipeline(inputs, vectordb, documents):
    """
    Chain of Thought ë°©ì‹ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰
    """
    print("\nğŸ“¥ ì…ë ¥ ì œì•ˆë¬¸:")
    print(inputs["generated_summary"])
    
    # 1. ì´ˆê¸° ìœ ì‚¬ë„ ê²€ìƒ‰ (CoTì—ì„œ ì°¸ì¡°í•  ë¬¸ì„œë“¤)
    print("\nâ±ï¸ [ìœ ì‚¬ë„ ê²€ìƒ‰] ì‹œì‘")
    start_time = time.time()
    
    # ê°„ë‹¨í•œ initial queryë¡œ top-10 ë¬¸ì„œ ê²€ìƒ‰
    top_10_docs = retrieve_context(inputs["generated_summary"])
    
    end_time = time.time()
    print(f"âœ… [ìœ ì‚¬ë„ ê²€ìƒ‰] ì™„ë£Œ - ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    
    # 2. Chain of Thought ì‹¤í–‰
    print("\nâ±ï¸ [Chain of Thought ë¶„ì„] ì‹œì‘")
    start_time = time.time()
    
    cot_result = llm.invoke(cot_prompt.format(
        components=inputs["components"],
        generated_summary=inputs["generated_summary"],
        top_10_documents=top_10_docs
    ))
    
    end_time = time.time()
    print(f"âœ… [Chain of Thought ë¶„ì„] ì™„ë£Œ - ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    
    return cot_result.content

# ICC ë°ì´í„°í”„ë ˆì„ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def update_icc_df(result_text, inputs, df, icc_df):
    """
    CoT ê²°ê³¼ì—ì„œ ICC íŒë³„ì‹œ ë°ì´í„°í”„ë ˆì„ ì—…ë°ì´íŠ¸
    """
    # ICC íŒë³„ ì—¬ë¶€ í™•ì¸
    if "íŒë‹¨ ê²°ê³¼:** ICC" in result_text:
        # ticket_idì™€ before/after_changeë¥¼ dfì—ì„œ ì°¾ê¸°
        ticket_row = df[df["generated_summary"] == inputs["generated_summary"]]
        if not ticket_row.empty:
            ticket_id = ticket_row.iloc[0].get("ticket_id_hashed", "")
            before_change = ticket_row.iloc[0].get("before_change", "")
            after_change = ticket_row.iloc[0].get("after_change", "")
        else:
            ticket_id = ""
            before_change = ""
            after_change = ""

        new_row = {
            "ticket_id": ticket_id,
            "components": inputs.get("components", ""),
            "before_change": before_change,
            "after_change": after_change,
            "ICC": "ICC"
        }
        icc_df = pd.concat([icc_df, pd.DataFrame([new_row])], ignore_index=True)
        
        print("ğŸ‘‰ íŒë³„ ê²°ê³¼ : ICC\n <ì¢…ë£Œ>")
        return True, icc_df
    
    return False, icc_df

# ìµœì¢… ê²°ê³¼ íŒŒì‹± í•¨ìˆ˜
def parse_final_result(result_text, inputs, df):
    """
    CoT ê²°ê³¼ì—ì„œ ìµœì¢… ì •ë³´ ì¶”ì¶œ
    """
    # ì„ íƒëœ ë¬¸ì„œì˜ ticket_id ì¶”ì¶œ
    match_ticket = re.search(r"âœ… ìµœì¢… ì¶”ì²œ ë¬¸ì„œ: \[(.*?)\]", result_text)
    ticket_id = match_ticket.group(1) if match_ticket else ""

    # RAGAS ì ìˆ˜ ì¶”ì¶œ
    match_ragas = re.search(r"ğŸ“Š RAG ê¸°ë°˜ ìœ ì‚¬ë„.*?:\s*(\d+)", result_text)
    ragas_score = int(match_ragas.group(1)) if match_ragas else 0

    # ì„ íƒëœ ë¬¸ì„œ ì •ë³´ ì¡°íšŒ
    selected_row = df[df["ticket_id_hashed"] == ticket_id]
    if not selected_row.empty:
        keyword = selected_row.iloc[0].get("keyword", "N/A")
        before_change = selected_row.iloc[0].get("before_change", "")
        after_change = selected_row.iloc[0].get("after_change", "")
    else:
        keyword = "N/A"
        before_change = ""
        after_change = ""

    return {
        "ticket_id": ticket_id,
        "components": inputs["components"],
        "before_change": before_change,
        "after_change": after_change,
        "generated_summary": inputs["generated_summary"],
        "ragas_score": ragas_score,
        "keyword": keyword
    }

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main(df, inputs):
    """
    Chain of Thought ë°©ì‹ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    # ë²¡í„°DB ì„¤ì •
    global vectordb, documents
    vectordb, documents = setup_vectordb(df)
    
    # ICC ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”
    icc_df = pd.DataFrame(columns=["ticket_id", "components", "before_change", "after_change", "ICC"])
    
    # CoT íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result_text = cot_pipeline(inputs, vectordb, documents)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ“Š Chain of Thought ë¶„ì„ ê²°ê³¼")
    print("="*50)
    print(result_text)
    
    # ICC ì²´í¬ ë° ì²˜ë¦¬
    is_icc, updated_icc_df = update_icc_df(result_text, inputs, df, icc_df)
    if is_icc:
        return None, updated_icc_df
    
    # Proposalì¸ ê²½ìš° ìµœì¢… ê²°ê³¼ íŒŒì‹±
    final_result = parse_final_result(result_text, inputs, df)
    return final_result, updated_icc_df

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°ì´í„° ë¡œë“œ (ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
    # df = pd.read_csv('your_data_path.csv', encoding='utf-8-sig')
    
    # # ì…ë ¥ ì˜ˆì‹œ
    # inputs = {
    #     "components": "ë¡œë´‡ì²­ì†Œê¸°",
    #     "generated_summary": "ThinkQ í‰ë©´ë„ìƒì— ì„ ì„ ê·¸ì–´ ì²­ì†Œêµ¬ì—­ì„ ì§€ì •í•˜ë„ë¡ í•´ì£¼ì„¸ìš”"
    # }
    
    # ì‹¤í–‰
    result, icc_df = main_cot(df, inputs)